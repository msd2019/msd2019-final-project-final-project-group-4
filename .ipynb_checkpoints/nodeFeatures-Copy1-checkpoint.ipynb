{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Node Feature Generation \n",
    "\n",
    "This script takes in raw data for each domain considered in this project and ultimately outputs a revised edgelist, a csv of node-level features, and a csv of edge-level features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declare functions for feature computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sign_out_degree(G, e_sign):\n",
    "    outdegree = defaultdict(int)\n",
    "    for u,v in ((u,v) for u,v,d in G.out_edges(data=True) if d['sign']==e_sign):\n",
    "        outdegree[u]+=1\n",
    "    return outdegree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sign_in_degree(G, e_sign):\n",
    "    indegree = defaultdict(int)\n",
    "    for u,v in ((u,v) for u,v,d in G.in_edges(data=True) if d['sign']==e_sign):\n",
    "        indegree[v] +=1\n",
    "    return indegree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_out_degree(G):\n",
    "    outdegree = defaultdict(int)\n",
    "    for i, j in G.out_degree():\n",
    "        outdegree[i] = j\n",
    "    return outdegree\n",
    "\n",
    "def total_in_degree(G):\n",
    "    indegree = defaultdict(int)\n",
    "    for i, j in G.in_degree():\n",
    "        indegree[i] = j\n",
    "    return indegree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "in_txt = csv.reader(open(\"data/epinions.txt\", \"r\"), delimiter = '\\t')\n",
    "for row in in_txt:\n",
    "        data.append(tuple(row))\n",
    "   \n",
    "df1 = pd.DataFrame(data, columns = ['u', 'v','sign']) \n",
    "G_epinions = nx.from_pandas_edgelist(df1, 'u', 'v', 'sign', create_using=nx.DiGraph())\n",
    "G_Und_epinions = nx.from_pandas_edgelist(df1, 'u', 'v', 'sign')\n",
    "\n",
    "pos_out = sign_out_degree(G_epinions, '1')\n",
    "neg_out = sign_out_degree(G_epinions, '-1')\n",
    "\n",
    "pos_in = sign_in_degree(G_epinions, '1')\n",
    "neg_in = sign_in_degree(G_epinions, '-1')\n",
    "\n",
    "total_out = total_out_degree(G_epinions)\n",
    "total_in = total_in_degree(G_epinions)\n",
    "\n",
    "ds = [total_out, total_in, pos_in, neg_in, pos_out,neg_out]\n",
    "my_dict = {}\n",
    "\n",
    "for k in total_out.keys():\n",
    "  my_dict[k] = tuple(my_dict[k] for my_dict in ds)\n",
    "\n",
    "with open('nodes_features_epinions.csv', 'w') as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    for key, value in my_dict.items():\n",
    "       writer.writerow([key, value])\n",
    "    \n",
    "nx.write_edgelist(G_Und_epinions, 'data/edgelist_epinions.csv', delimiter = ',', data = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in epinions data and compute node-level features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "in_txt = csv.reader(open(\"data/slashdot.txt\", \"r\"), delimiter = '\\t')\n",
    "for row in in_txt:\n",
    "        data.append(tuple(row))\n",
    "   \n",
    "df1 = pd.DataFrame(data, columns = ['u', 'v','sign']) \n",
    "G_slashdot = nx.from_pandas_edgelist(df1, 'u', 'v', 'sign', create_using=nx.DiGraph())\n",
    "G_Und_slashdot = nx.from_pandas_edgelist(df1, 'u', 'v', 'sign')\n",
    "\n",
    "pos_out = sign_out_degree(G_slashdot, '1')\n",
    "neg_out = sign_out_degree(G_slashdot, '-1')\n",
    "\n",
    "pos_in = sign_in_degree(G_slashdot, '1')\n",
    "neg_in = sign_in_degree(G_slashdot, '-1')\n",
    "\n",
    "total_out = total_out_degree(G_slashdot)\n",
    "total_in = total_in_degree(G_slashdot)\n",
    "\n",
    "ds = [total_out, total_in, pos_in, neg_in, pos_out,neg_out]\n",
    "my_dict = {}\n",
    "\n",
    "for k in total_out.keys():\n",
    "  my_dict[k] = tuple(my_dict[k] for my_dict in ds)\n",
    "\n",
    "with open('nodes_features_slashdot.csv', 'w') as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    for key, value in my_dict.items():\n",
    "       writer.writerow([key, value])\n",
    "    \n",
    "nx.write_edgelist(G_Und_slashdot, 'data/edgelist_slashdot.csv', delimiter = ',', data = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in provided Wikipedia data and compute node-level features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "in_txt = csv.reader(open(\"data/wiki-utf.txt\", \"r\"), delimiter = '\\t')\n",
    "\n",
    "v = \"\"\n",
    "\n",
    "for row in in_txt:\n",
    "    if(len(row)!=0 and row[0]=='U'):\n",
    "        v = row[1]\n",
    "        \n",
    "    if(len(row)!=0 and row[0]=='V'):\n",
    "        newuple = (row[2],v,row[1])\n",
    "        data.append(newuple)\n",
    "        \n",
    "df1 = pd.DataFrame(data, columns = ['u', 'v','sign']) \n",
    "\n",
    "G_old_wiki = nx.from_pandas_edgelist(df1, 'u', 'v', 'sign', create_using=nx.DiGraph())\n",
    "G_Und_old_wiki = nx.from_pandas_edgelist(df1, 'u', 'v', 'sign')\n",
    "\n",
    "pos_out = sign_out_degree(G_old_wiki, '1')\n",
    "neg_out = sign_out_degree(G_old_wiki, '-1')\n",
    "\n",
    "pos_in = sign_in_degree(G_old_wiki, '1')\n",
    "neg_in = sign_in_degree(G_old_wiki, '-1')\n",
    "\n",
    "total_out = total_out_degree(G_old_wiki)\n",
    "total_in = total_in_degree(G_old_wiki)\n",
    "\n",
    "ds = [total_out, total_in, pos_in, neg_in, pos_out,neg_out]\n",
    "my_dict = {}\n",
    "\n",
    "for k in total_out.keys():\n",
    "  my_dict[k] = tuple(my_dict[k] for my_dict in ds)\n",
    "\n",
    "with open('nodes_features_oldwiki.csv', 'w') as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    for key, value in my_dict.items():\n",
    "       writer.writerow([key, value])\n",
    "\n",
    "nx.write_edgelist(G_Und_old_wiki, 'data/edgelist_oldwiki.csv', delimiter = ',', data = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in new Wikipedia data and compute node-level features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "in_txt = csv.reader(open(\"data/newwiki_edgelist.csv\", \"r\"))\n",
    "for row in in_txt:\n",
    "        data.append(tuple(row))\n",
    "   \n",
    "df1 = pd.DataFrame(data, columns = ['u', 'v','sign']) \n",
    "\n",
    "G_new_wiki = nx.from_pandas_edgelist(df1, 'u', 'v', 'sign', create_using=nx.DiGraph())\n",
    "G_Und_new_wiki = nx.from_pandas_edgelist(df1, 'u', 'v', 'sign')\n",
    "\n",
    "pos_out = sign_out_degree(G_new_wiki, '1')\n",
    "neg_out = sign_out_degree(G_new_wiki, '-1')\n",
    "\n",
    "pos_in = sign_in_degree(G_new_wiki, '1')\n",
    "neg_in = sign_in_degree(G_new_wiki, '-1')\n",
    "\n",
    "total_out = total_out_degree(G_new_wiki)\n",
    "total_in = total_in_degree(G_new_wiki)\n",
    "\n",
    "ds = [total_out, total_in, pos_in, neg_in, pos_out,neg_out]\n",
    "my_dict = {}\n",
    "\n",
    "for k in total_out.keys():\n",
    "  my_dict[k] = tuple(my_dict[k] for my_dict in ds)\n",
    "\n",
    "with open('nodes_features_newwiki.csv', 'w') as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    for key, value in my_dict.items():\n",
    "       writer.writerow([key, value])\n",
    "    \n",
    "nx.write_edgelist(G_Und_new_wiki, 'data/edgelist_newwiki.csv', delimiter = ',', data = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in Bitcoin data and compute node-level features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "in_txt = csv.reader(open(\"data/soc-sign-bitcoinotc.csv\", \"r\"))\n",
    "for row in in_txt:\n",
    "        data.append(tuple(row))\n",
    "   \n",
    "df1 = pd.DataFrame(data, columns = ['u', 'v','sign']) \n",
    "df1['sign'] = df1['sign'].astype(int)\n",
    "df1.loc[df1.sign < 0, 'sign'] = 0 \n",
    "df1.loc[df1.sign > 0, 'sign'] = 1 \n",
    "\n",
    "G_bitcoin = nx.from_pandas_edgelist(df1, 'u', 'v', 'sign', create_using=nx.DiGraph())\n",
    "G_Und_bitcoin = nx.from_pandas_edgelist(df1, 'u', 'v', 'sign')\n",
    "\n",
    "pos_out = sign_out_degree(G_bitcoin, '1')\n",
    "neg_out = sign_out_degree(G_bitcoin, '-1')\n",
    "\n",
    "pos_in = sign_in_degree(G_bitcoin, '1')\n",
    "neg_in = sign_in_degree(G_bitcoin, '-1')\n",
    "\n",
    "total_out = total_out_degree(G_bitcoin)\n",
    "total_in = total_in_degree(G_bitcoin)\n",
    "\n",
    "ds = [total_out, total_in, pos_in, neg_in, pos_out,neg_out]\n",
    "my_dict = {}\n",
    "\n",
    "for k in total_out.keys():\n",
    "  my_dict[k] = tuple(my_dict[k] for my_dict in ds)\n",
    "\n",
    "with open('data/nodes_features_bitcoin.csv', 'w') as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    for key, value in my_dict.items():\n",
    "       writer.writerow([key, value])\n",
    "\n",
    "nx.write_edgelist(G_Und_bitcoin, 'data/edgelist_bitcoin.csv', delimiter = ',', data = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute edge-level embeddedness feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embeddedness(G):\n",
    "    embeddedness = []\n",
    "    for u,v in G.edges():\n",
    "        embeddedness.append([u,v,str(len(list(nx.common_neighbors(G,u,v))))])\n",
    "    return embeddedness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded = embeddedness(G_Und_epinions)\n",
    "\n",
    "with open(\"edges_features_epinions.csv\", \"w\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"u\", \"v\", \"embeddedness\"])\n",
    "    writer.writerows(embedded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded = embeddedness(G_Und_slashdot)\n",
    "\n",
    "with open(\"edges_features_slashdot.csv\", \"w\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"u\", \"v\", \"embeddedness\"])\n",
    "    writer.writerows(embedded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded = embeddedness(G_Und_old_wiki)\n",
    "\n",
    "with open(\"edges_features_old_wiki.csv\", \"w\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"u\", \"v\", \"embeddedness\"])\n",
    "    writer.writerows(embedded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded = embeddedness(G_Und_new_wiki)\n",
    "\n",
    "with open(\"edges_features_new_wiki.csv\", \"w\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"u\", \"v\", \"embeddedness\"])\n",
    "    writer.writerows(embedded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded = embeddedness(G_Und_bitcoin)\n",
    "\n",
    "with open(\"edges_features_bitcoin.csv\", \"w\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"u\", \"v\", \"embeddedness\"])\n",
    "    writer.writerows(embedded)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
